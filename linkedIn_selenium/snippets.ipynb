{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "txt = \"LinkedIn: Log In or Sign Up\"\n",
    "pattern = re.compile(r\"log\\s?-?in|sign\\s?-?in|sign\\s?-?up\",re.IGNORECASE)\n",
    "m = pattern.search(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/selenium_scrap_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[268,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.loc[df[\"apply_link\"].filter(regex=r\".*\")][\"apply_link\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "# from seleniumwire import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException,WebDriverException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "# options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "try:\n",
    "    driver.get(\"https://www.google.com\")\n",
    "except WebDriverException as e:\n",
    "    print(e.args)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get('chrome-extension://eimadpbcbfnmbkopoojfekhnkhdbieeh/ui/popup/index.html')\n",
    "driver.switch_to.frame(driver.find_element(By.TAG_NAME,\"iframe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "els = driver.find_elements(By.XPATH, \"//span[text()[contains(.,'Show qualification details')]]/parent::button\")\n",
    "print(len(els))\n",
    "for e in els:\n",
    "    e.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception(\"shite\",\"ok\")\n",
    "except Exception as e:\n",
    "    print(e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "df = pd.read_csv(\"results/selenium_scrap_results.csv\",converters={\"skills\":literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from linkedIn_selenium.matcher import fuzz_match, find_matches\n",
    "df[\"match_score\"] = df[\"skills\"].apply(func=lambda x: fuzz_match(x,my_skills,method='partial'))\n",
    "df[\"match_score\"].describe()\n",
    "df[\"top_matches\"] = df[\"skills\"].apply(func=lambda x: find_matches(x,my_skills,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from linkedIn_selenium.db import get_crawl_time_id, get_original_query_id,insert_details\n",
    "crawl_time_id = get_crawl_time_id(datetime.now().isoformat(timespec='minutes'))\n",
    "original_query_id = get_original_query_id(\"Sag pedar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.sample().to_dict(orient='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['salam','gooz']\n",
    "a = \"'\"+\"','\".join(data)+\"'\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from linkedIn_selenium.db import DB\n",
    "from linkedIn_selenium.matcher import fuzz_match, find_matches\n",
    "\n",
    "db = DB(\"jobs.sqlite\")\n",
    "my_skills = dotenv.get_key(\".env\",\"MY_SKILLS\")\n",
    "assert my_skills is not None\n",
    "my_skills = literal_eval(my_skills)\n",
    "db.create_tables()\n",
    "df = pd.read_csv(\"results/selenium_scrap_results.csv\",converters={\"skills\":literal_eval})\n",
    "df.replace({np.nan:None},inplace=True)\n",
    "df[\"match_score\"] = df[\"skills\"].apply(func=lambda x: fuzz_match(x,my_skills,method='partial'))\n",
    "df[\"top_matches\"] = df[\"skills\"].apply(func=lambda x: find_matches(x,my_skills,70))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"top_matches\"].isna()]\n",
    "for ind,row in df.to_dict('index').items():\n",
    "    company_id = db.get_company_id(row.pop('company_name'))\n",
    "    original_query_id = db.get_original_query_id(row.pop('original_query'))\n",
    "    crawl_time_id = db.get_crawl_time_id(row.pop('crawl_time'))\n",
    "    db.insert_details(**row,company_id=company_id,\n",
    "                    original_query_id=original_query_id, crawl_time_id=crawl_time_id,match_threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "q = \" CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, j JSONB);\"\n",
    "conn = sqlite3.connect(\"sagz.sqlite\")\n",
    "conn.execute(q)\n",
    "data = ['salam','gooz']\n",
    "data = \"'\"+\"','\".join(data)+\"'\"\n",
    "conn.execute(f\"INSERT INTO test (j) VALUES (json_array({data}));\")\n",
    "conn.commit()\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM test;\")\n",
    "res = c.fetchone()\n",
    "print(json.loads(res[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Back-End Web Development', 'JavaScript']\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"jobs.sqlite\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM details;\")\n",
    "res = c.fetchone()\n",
    "print(json.loads(res[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_id': 3855050325,\n",
       " 'title': 'Sr. Front End Engineer',\n",
       " 'name': 'Aha!',\n",
       " 'post_time': '2024-03-13 07:44:00',\n",
       " 'n_applicants': None,\n",
       " 'location': 'Canada',\n",
       " 'skills': 'Back-End Web Development,Cascading Style Sheets (CSS),Documentation,Front-End Development,HTML,Model-View-Controller (MVC),Problem Solving,Slide Preparation,User Experience (UX),User Interface Design',\n",
       " 'is_repost': 0,\n",
       " 'apply_link': 'https://www.aha.io/company/careers/current-openings/front-end-developer-remote',\n",
       " 'post_time_raw': '11 hours ago',\n",
       " 'li_job_link': 'https://www.linkedin.com/jobs/view/3855050325/',\n",
       " 'time': '2024-03-13 19:00:00',\n",
       " 'match_score': 41,\n",
       " 'top_matches': '[\"Back-End Web Development\",\"Front-End Development\"]',\n",
       " 'match_threshold': 70,\n",
       " 'query': 'junior python data engineer'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-11 11:00:00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "t.strftime('%Y-%m-%d %H:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x720770311140>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from linkedIn_selenium.db import DB\n",
    "db = DB(\"results/jobs.sqlite\")\n",
    "res = db.exists(3855009164)\n",
    "print(res)\n",
    "db.conn.execute(\"CREATE UNIQUE INDEX unique_job_id ON details(job_id);\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
