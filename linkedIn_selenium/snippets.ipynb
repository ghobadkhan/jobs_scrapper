{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract apply link domains\n",
    "\n",
    "The following code extract the domain of apply links. The extraction is used to decide which apply boards are mostly used. I'm aiming to automate the application process at these job boards.\n",
    "\n",
    "__DON'T REMOVE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apply_board\n",
       "greenhouse.io              31\n",
       "jobdiva.com                14\n",
       "myworkdayjobs.com          13\n",
       "lumenalta.com              11\n",
       "clickjobs.io               11\n",
       "ashbyhq.com                11\n",
       "procomservices.com          9\n",
       "ceipal.com                  9\n",
       "crossover.com               8\n",
       "scotiabank.com              7\n",
       "lever.co                    6\n",
       "spglobal.com                5\n",
       "aha.io                      5\n",
       "recruiterflow.com           5\n",
       "mygwork.com                 4\n",
       "newrelic.careers            3\n",
       "amazon.jobs                 2\n",
       "recruitee.com               2\n",
       "dayforcehcm.com             2\n",
       "stripe.com                  2\n",
       "talentnet.community         2\n",
       "pharmiweb.jobs              2\n",
       "lifelabs.com                2\n",
       "apexsystems.com             2\n",
       "opentext.com                2\n",
       "raise.jobs                  1\n",
       "contacthr.com               1\n",
       "demonware.net               1\n",
       "celestica.com               1\n",
       "indexexchange.com           1\n",
       "adp.com                     1\n",
       "energyjobline.com           1\n",
       "ismartrecruit.com           1\n",
       "breezy.hr                   1\n",
       "sproutsocial.com            1\n",
       "ideogram.ai                 1\n",
       "zohorecruit.com             1\n",
       "roche.com                   1\n",
       "macrohealth.com             1\n",
       "jobvite.com                 1\n",
       "thejobnetwork.com           1\n",
       "w3global.ca                 1\n",
       "lrostaffing.com             1\n",
       "careerbeacon.com            1\n",
       "talentlyft.com              1\n",
       "ultipro.ca                  1\n",
       "usebraintrust.com           1\n",
       "anvil.ai                    1\n",
       "wawanesa.com                1\n",
       "talent.com                  1\n",
       "mantu.com                   1\n",
       "bamboohr.com                1\n",
       "salesforce-sites.com        1\n",
       "ieso.ca                     1\n",
       "quartech.com                1\n",
       "bc.ca                       1\n",
       "breezy-mail.com             1\n",
       "kongsbergautomotive.com     1\n",
       "bentley.com                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from linkedIn_selenium.db import DB\n",
    "import re\n",
    "\n",
    "db = DB(\"results/jobs.sqlite\")\n",
    "# https://something.domain.com/blahblahblah -> domain.com\n",
    "pat = re.compile(r\"https?:\\/\\/(.*\\.)?(.*\\..*?)\\/.*\")\n",
    "q = \"\"\"\n",
    "SELECT d.id, d.apply_link, c.name FROM details as d \n",
    "LEFT JOIN company as c ON d.company_id = c.id\n",
    "WHERE apply_link IS NOT NULL;\n",
    "\"\"\"\n",
    "db.cursor.execute(q)\n",
    "raw = db.cursor.fetchall()\n",
    "df = pd.DataFrame(columns=[\"id\",\"apply_link\",\"company_name\"],data=raw)\n",
    "df[\"apply_board\"] = df[\"apply_link\"].apply(lambda lnk: pat.findall(lnk)[0][-1])\n",
    "df['apply_board'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "txt = \"LinkedIn: Log In or Sign Up\"\n",
    "pattern = re.compile(r\"log\\s?-?in|sign\\s?-?in|sign\\s?-?up\",re.IGNORECASE)\n",
    "m = pattern.search(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/selenium_scrap_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[268,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.loc[df[\"apply_link\"].filter(regex=r\".*\")][\"apply_link\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "# from seleniumwire import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException,WebDriverException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "# options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "try:\n",
    "    driver.get(\"https://www.google.com\")\n",
    "except WebDriverException as e:\n",
    "    print(e.args)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get('chrome-extension://eimadpbcbfnmbkopoojfekhnkhdbieeh/ui/popup/index.html')\n",
    "driver.switch_to.frame(driver.find_element(By.TAG_NAME,\"iframe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "els = driver.find_elements(By.XPATH, \"//span[text()[contains(.,'Show qualification details')]]/parent::button\")\n",
    "print(len(els))\n",
    "for e in els:\n",
    "    e.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception(\"shite\",\"ok\")\n",
    "except Exception as e:\n",
    "    print(e.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "df = pd.read_csv(\"results/selenium_scrap_results.csv\",converters={\"skills\":literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from linkedIn_selenium.matcher import fuzz_match, find_matches\n",
    "df[\"match_score\"] = df[\"skills\"].apply(func=lambda x: fuzz_match(x,my_skills,method='partial'))\n",
    "df[\"match_score\"].describe()\n",
    "df[\"top_matches\"] = df[\"skills\"].apply(func=lambda x: find_matches(x,my_skills,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from linkedIn_selenium.db import get_crawl_time_id, get_original_query_id,insert_details\n",
    "crawl_time_id = get_crawl_time_id(datetime.now().isoformat(timespec='minutes'))\n",
    "original_query_id = get_original_query_id(\"Sag pedar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.sample().to_dict(orient='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['salam','gooz']\n",
    "a = \"'\"+\"','\".join(data)+\"'\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_board\n",
       "greenhouse.io              31\n",
       "jobdiva.com                14\n",
       "myworkdayjobs.com          13\n",
       "lumenalta.com              11\n",
       "clickjobs.io               11\n",
       "ashbyhq.com                11\n",
       "procomservices.com          9\n",
       "ceipal.com                  9\n",
       "crossover.com               8\n",
       "scotiabank.com              7\n",
       "lever.co                    6\n",
       "spglobal.com                5\n",
       "aha.io                      5\n",
       "recruiterflow.com           5\n",
       "mygwork.com                 4\n",
       "newrelic.careers            3\n",
       "amazon.jobs                 2\n",
       "recruitee.com               2\n",
       "dayforcehcm.com             2\n",
       "stripe.com                  2\n",
       "talentnet.community         2\n",
       "pharmiweb.jobs              2\n",
       "lifelabs.com                2\n",
       "apexsystems.com             2\n",
       "opentext.com                2\n",
       "raise.jobs                  1\n",
       "contacthr.com               1\n",
       "demonware.net               1\n",
       "celestica.com               1\n",
       "indexexchange.com           1\n",
       "adp.com                     1\n",
       "energyjobline.com           1\n",
       "ismartrecruit.com           1\n",
       "breezy.hr                   1\n",
       "sproutsocial.com            1\n",
       "ideogram.ai                 1\n",
       "zohorecruit.com             1\n",
       "roche.com                   1\n",
       "macrohealth.com             1\n",
       "jobvite.com                 1\n",
       "thejobnetwork.com           1\n",
       "w3global.ca                 1\n",
       "lrostaffing.com             1\n",
       "careerbeacon.com            1\n",
       "talentlyft.com              1\n",
       "ultipro.ca                  1\n",
       "usebraintrust.com           1\n",
       "anvil.ai                    1\n",
       "wawanesa.com                1\n",
       "talent.com                  1\n",
       "mantu.com                   1\n",
       "bamboohr.com                1\n",
       "salesforce-sites.com        1\n",
       "ieso.ca                     1\n",
       "quartech.com                1\n",
       "bc.ca                       1\n",
       "breezy-mail.com             1\n",
       "kongsbergautomotive.com     1\n",
       "bentley.com                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"top_matches\"].isna()]\n",
    "for ind,row in df.to_dict('index').items():\n",
    "    company_id = db.get_company_id(row.pop('company_name'))\n",
    "    original_query_id = db.get_original_query_id(row.pop('original_query'))\n",
    "    crawl_time_id = db.get_crawl_time_id(row.pop('crawl_time'))\n",
    "    db.insert_details(**row,company_id=company_id,\n",
    "                    original_query_id=original_query_id, crawl_time_id=crawl_time_id,match_threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "q = \" CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, j JSONB);\"\n",
    "conn = sqlite3.connect(\"sagz.sqlite\")\n",
    "conn.execute(q)\n",
    "data = ['salam','gooz']\n",
    "data = \"'\"+\"','\".join(data)+\"'\"\n",
    "conn.execute(f\"INSERT INTO test (j) VALUES (json_array({data}));\")\n",
    "conn.commit()\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM test;\")\n",
    "res = c.fetchone()\n",
    "print(json.loads(res[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Back-End Web Development', 'JavaScript']\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"jobs.sqlite\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM details;\")\n",
    "res = c.fetchone()\n",
    "print(json.loads(res[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_id': 3855050325,\n",
       " 'title': 'Sr. Front End Engineer',\n",
       " 'name': 'Aha!',\n",
       " 'post_time': '2024-03-13 07:44:00',\n",
       " 'n_applicants': None,\n",
       " 'location': 'Canada',\n",
       " 'skills': 'Back-End Web Development,Cascading Style Sheets (CSS),Documentation,Front-End Development,HTML,Model-View-Controller (MVC),Problem Solving,Slide Preparation,User Experience (UX),User Interface Design',\n",
       " 'is_repost': 0,\n",
       " 'apply_link': 'https://www.aha.io/company/careers/current-openings/front-end-developer-remote',\n",
       " 'post_time_raw': '11 hours ago',\n",
       " 'li_job_link': 'https://www.linkedin.com/jobs/view/3855050325/',\n",
       " 'time': '2024-03-13 19:00:00',\n",
       " 'match_score': 41,\n",
       " 'top_matches': '[\"Back-End Web Development\",\"Front-End Development\"]',\n",
       " 'match_threshold': 70,\n",
       " 'query': 'junior python data engineer'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-11 11:00:00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "t.strftime('%Y-%m-%d %H:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x720770311140>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from linkedIn_selenium.db import DB\n",
    "db = DB(\"results/jobs.sqlite\")\n",
    "res = db.exists(3855009164)\n",
    "print(res)\n",
    "db.conn.execute(\"CREATE UNIQUE INDEX unique_job_id ON details(job_id);\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
